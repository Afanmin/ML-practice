{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test , y_train_all, y_test = train_test_split(\n",
    "    housing.data,housing.target,random_state = 7)\n",
    "x_train , x_valid , y_train , y_valid = train_test_split(\n",
    "    x_train_all,y_train_all,random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 30)           210         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 30)           930         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 35)           0           input_13[0][0]                   \n",
      "                                                                 dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            36          concatenate_6[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_wide = keras.layers.Input(shape = [5])\n",
    "input_deep = keras.layers.Input(shape = [6])\n",
    "hidden1 = keras.layers.Dense(30,activation='relu')(input_deep)\n",
    "hidden2 = keras.layers.Dense(30,activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_wide,hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = keras.models.Model(inputs = [input_wide,input_deep],outputs=[output])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error',optimizer = 'adam')#用sgd无法收敛\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=5,min_delta=1e-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 1.5616 - val_loss: 0.7034\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.5188 - val_loss: 0.4852\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.4403 - val_loss: 0.4339\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4104 - val_loss: 0.4140\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3981 - val_loss: 0.4004\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3806 - val_loss: 0.3906\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3785 - val_loss: 0.3776\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3624 - val_loss: 0.3722\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3591 - val_loss: 0.3669\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3558 - val_loss: 0.3692\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3496 - val_loss: 0.3637\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3485 - val_loss: 0.3547\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3397 - val_loss: 0.3555\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3363 - val_loss: 0.3442\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3339 - val_loss: 0.3411\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3341 - val_loss: 0.3398\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3335 - val_loss: 0.3506\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3292 - val_loss: 0.3412\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3263 - val_loss: 0.3351\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train_scaled[:,:5],x_train_scaled[:,2:]],y_train,validation_data=([x_valid_scaled[:,:5],x_valid_scaled[:,2:]],y_valid),\n",
    "                   epochs=100,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
