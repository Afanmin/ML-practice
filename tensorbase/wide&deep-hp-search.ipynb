{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test , y_train_all, y_test = train_test_split(\n",
    "    housing.data,housing.target,random_state = 7)\n",
    "x_train , x_valid , y_train , y_valid = train_test_split(\n",
    "    x_train_all,y_train_all,random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 2s 140us/sample - loss: 4.8875 - val_loss: 3.8385\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 2.5981 - val_loss: 2.1348\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 1.6092 - val_loss: 1.5196\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 1.2339 - val_loss: 1.2150\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 1.0237 - val_loss: 1.0174\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.8739 - val_loss: 0.8792\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.7642 - val_loss: 0.7772\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.6869 - val_loss: 0.7086\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.6326 - val_loss: 0.6587\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.5945 - val_loss: 0.6216\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.5659 - val_loss: 0.5914\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5429 - val_loss: 0.5666\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.5242 - val_loss: 0.5457\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.5077 - val_loss: 0.5300\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4932 - val_loss: 0.5135\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.4803 - val_loss: 0.4993\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.4688 - val_loss: 0.4865\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.4585 - val_loss: 0.4760\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4493 - val_loss: 0.4659\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.4410 - val_loss: 0.4581\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4335 - val_loss: 0.4508\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4270 - val_loss: 0.4447\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.4208 - val_loss: 0.4365\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.4151 - val_loss: 0.4313\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4105 - val_loss: 0.4254\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.4062 - val_loss: 0.4208\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4022 - val_loss: 0.4162\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3983 - val_loss: 0.4131\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3946 - val_loss: 0.4103\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3919 - val_loss: 0.4066\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3888 - val_loss: 0.4042\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3862 - val_loss: 0.4019\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3839 - val_loss: 0.3980\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3817 - val_loss: 0.3946\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3796 - val_loss: 0.3927\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - ETA: 0s - loss: 0.380 - 1s 57us/sample - loss: 0.3773 - val_loss: 0.3906\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3756 - val_loss: 0.3891\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3737 - val_loss: 0.3875\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3722 - val_loss: 0.3854\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3705 - val_loss: 0.3829\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3692 - val_loss: 0.3811\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 3.7188 - val_loss: 2.3234\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 1.7720 - val_loss: 1.6368\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 1.2947 - val_loss: 1.2216\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.9784 - val_loss: 0.9461\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.7770 - val_loss: 0.7717\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.6491 - val_loss: 0.6442\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.5742 - val_loss: 0.5768\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.5262 - val_loss: 0.5337\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4929 - val_loss: 0.5005\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.4677 - val_loss: 0.4745\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.4490 - val_loss: 0.4573\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4326 - val_loss: 0.4444\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4206 - val_loss: 0.4311\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.4095 - val_loss: 0.4202\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4008 - val_loss: 0.4140\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3939 - val_loss: 0.4046\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3875 - val_loss: 0.4027\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3821 - val_loss: 0.3939\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3792 - val_loss: 0.3898\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3732 - val_loss: 0.3867\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3685 - val_loss: 0.3870\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3674 - val_loss: 0.3811\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3654 - val_loss: 0.3782\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3611 - val_loss: 0.3745\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3573 - val_loss: 0.3713\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3556 - val_loss: 0.3715\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3549 - val_loss: 0.3679\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3514 - val_loss: 0.3661\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3501 - val_loss: 0.3652\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3487 - val_loss: 0.3628\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3454 - val_loss: 0.3614\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3432 - val_loss: 0.3613\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 102us/sample - loss: 1.2315 - val_loss: 0.5588\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4496 - val_loss: 0.4461\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.4105 - val_loss: 0.4189\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.4034 - val_loss: 0.4101\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3982 - val_loss: 0.4014\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3814 - val_loss: 0.3967\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3718 - val_loss: 0.3818\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3711 - val_loss: 0.3748\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3628 - val_loss: 0.3783\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3525 - val_loss: 0.3580\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3515 - val_loss: 0.3629\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3657 - val_loss: 0.3566\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3479 - val_loss: 0.3503\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3398 - val_loss: 0.3555\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3423 - val_loss: 0.3579\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 91us/sample - loss: 0.7224 - val_loss: 0.4497\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.4459 - val_loss: 0.4466\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.4003 - val_loss: 0.4266\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3750 - val_loss: 0.3814\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3612 - val_loss: 0.3673\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3662 - val_loss: 0.5486\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3609 - val_loss: 0.3620\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3432 - val_loss: 0.3387\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.3415 - val_loss: 0.3488\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3447 - val_loss: 0.3433\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3239 - val_loss: 0.3383\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3288 - val_loss: 0.3481\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3242 - val_loss: 0.3299\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 92us/sample - loss: 0.6092 - val_loss: 0.4521\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4183 - val_loss: 0.4387\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4020 - val_loss: 0.3783\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3717 - val_loss: 0.3774\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3797 - val_loss: 0.4933\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3587 - val_loss: 0.3443\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3494 - val_loss: 0.3524\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3491 - val_loss: 0.3740\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3434 - val_loss: 0.3459\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3462 - val_loss: 0.3806\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3619 - val_loss: 0.8989\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 88us/sample - loss: 0.6424 - val_loss: 0.4318\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4859 - val_loss: 0.4051\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.4726 - val_loss: 0.4308\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4235 - val_loss: 0.5045\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3816 - val_loss: 0.3778\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3655 - val_loss: 0.3825\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3660 - val_loss: 0.3534\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3698 - val_loss: 0.3605\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.3502 - val_loss: 0.3834\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3678 - val_loss: 0.4431\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3827 - val_loss: 0.3547\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 0.3496 - val_loss: 0.3411\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 83us/sample - loss: 0.5214 - val_loss: 0.4198\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 85us/sample - loss: 0.3817 - val_loss: 0.4029\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 0.3614 - val_loss: 0.3604\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 0.3607 - val_loss: 0.3847\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.3540 - val_loss: 0.3509\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [1e-4,3e-4,1e-3,3e-3,1e-2,3e-2]\n",
    "hist =[]\n",
    "for lr in learning_rate:\n",
    "\n",
    "    input_wide = keras.layers.Input(shape = [5])\n",
    "    input_deep = keras.layers.Input(shape = [6])\n",
    "    hidden1 = keras.layers.Dense(30,activation='relu')(input_deep)\n",
    "    hidden2 = keras.layers.Dense(30,activation='relu')(hidden1)\n",
    "    concat = keras.layers.concatenate([input_wide,hidden2])\n",
    "    output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "    model = keras.models.Model(inputs = [input_wide,input_deep],outputs=[output])\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "#model.summary()\n",
    "    model.compile(loss='mean_squared_error',optimizer = optimizer)#用sgd无法收敛\n",
    "    \n",
    "    callbacks = [keras.callbacks.EarlyStopping(patience=5,min_delta=1e-2)]\n",
    "    \n",
    "    history = model.fit([x_train_scaled[:,:5],x_train_scaled[:,2:]],y_train,validation_data=([x_valid_scaled[:,:5],x_valid_scaled[:,2:]],y_valid),\n",
    "                   epochs=100,callbacks=callbacks)\n",
    "    hist.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 1s 114us/sample - loss: 1.5616 - val_loss: 0.7034\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.5188 - val_loss: 0.4852\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.4403 - val_loss: 0.4339\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4104 - val_loss: 0.4140\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.3981 - val_loss: 0.4004\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3806 - val_loss: 0.3906\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3785 - val_loss: 0.3776\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 0.3624 - val_loss: 0.3722\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3591 - val_loss: 0.3669\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3558 - val_loss: 0.3692\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3496 - val_loss: 0.3637\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3485 - val_loss: 0.3547\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3397 - val_loss: 0.3555\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3363 - val_loss: 0.3442\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.3339 - val_loss: 0.3411\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3341 - val_loss: 0.3398\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3335 - val_loss: 0.3506\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3292 - val_loss: 0.3412\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.3263 - val_loss: 0.3351\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train_scaled[:,:5],x_train_scaled[:,2:]],y_train,validation_data=([x_valid_scaled[:,:5],x_valid_scaled[:,2:]],y_valid),\n",
    "                   epochs=100,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
