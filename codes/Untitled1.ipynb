{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 0\n",
      "第 100 步的平均损失 0.5136012321710587\n",
      "第 200 步的平均损失 0.479248902797699\n",
      "第 300 步的平均损失 0.4775157281756401\n",
      "第 400 步的平均损失 0.47407052338123323\n",
      "\n",
      "epoch 1\n",
      "第 100 步的平均损失 0.47670484483242037\n",
      "第 200 步的平均损失 0.46972216457128524\n",
      "第 300 步的平均损失 0.4691995307803154\n",
      "第 400 步的平均损失 0.4640889230370522\n",
      "\n",
      "epoch 2\n",
      "第 100 步的平均损失 0.4690506038069725\n",
      "第 200 步的平均损失 0.46179756134748456\n",
      "第 300 步的平均损失 0.46232962757349017\n",
      "第 400 步的平均损失 0.46088230192661284\n",
      "\n",
      "epoch 3\n",
      "第 100 步的平均损失 0.46635102659463884\n",
      "第 200 步的平均损失 0.45903229504823684\n",
      "第 300 步的平均损失 0.4589355778694153\n",
      "第 400 步的平均损失 0.4594328036904335\n",
      "\n",
      "epoch 4\n",
      "第 100 步的平均损失 0.4670567384362221\n",
      "第 200 步的平均损失 0.45916874408721925\n",
      "第 300 步的平均损失 0.45915147572755816\n",
      "第 400 步的平均损失 0.45848305106163023\n",
      "0.513601232171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117616c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''超参数'''\n",
    "num_steps = 10\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 16\n",
    "learning_rate = 0.1\n",
    "\n",
    "'''生成数据\n",
    "就是按照文章中提到的规则，这里生成1000000个\n",
    "'''\n",
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    '''根据规则生成Y'''\n",
    "    for i in range(size):   \n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -=0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "\n",
    "'''生成batch数据'''\n",
    "def gen_batch(raw_data, batch_size, num_step):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "    batch_patition_length = data_length // batch_size                         # ->5000\n",
    "    data_x = np.zeros([batch_size, batch_patition_length], dtype=np.int32)    # ->(200, 5000)\n",
    "    data_y = np.zeros([batch_size, batch_patition_length], dtype=np.int32)    # ->(200, 5000)\n",
    "    '''填到矩阵的对应位置'''\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_patition_length*i:batch_patition_length*(i+1)]# 每一行取batch_patition_length个数，即5000\n",
    "        data_y[i] = raw_y[batch_patition_length*i:batch_patition_length*(i+1)]\n",
    "    epoch_size = batch_patition_length // num_steps                           # ->5000/5=1000 就是每一轮的大小\n",
    "    for i in range(epoch_size):   # 抽取 epoch_size 个数据\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]                      # ->(200, 5)\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)    # yield 是生成器，生成器函数在生成值后会自动挂起并暂停他们的执行和状态（最后就是for循环结束后的结果，共有1000个(x, y)）\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)\n",
    "\n",
    "'''定义placeholder'''\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name=\"x\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='y')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "'''RNN输入'''\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "\n",
    "'''定义RNN cell'''\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes+state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat([rnn_input, state],1),W) + b)\n",
    "'''将rnn cell添加到计算图中'''\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)  # state会重复使用，循环\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]        # 得到最后的state\n",
    "\n",
    "#cell = tf.contrib.rnn.BasicRNNCell(num_units=state_size)\n",
    "#rnn_outputs, final_state = tf.contrib.rnn.static_rnn(cell=cell, inputs=rnn_inputs, \n",
    "                                                    #initial_state=init_state)\n",
    "#rnn_outputs, final_state = tf.nn.dynamic_rnn(cell=cell, inputs=rnn_inputs, \n",
    "                                                    #initial_state=init_state)\n",
    "\n",
    "\n",
    "'''预测，损失，优化'''\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label,logits=logit) for logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "\n",
    "'''训练网络'''\n",
    "def train_rnn(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))   # ->(200, 4)\n",
    "            if verbose:\n",
    "                print('\\nepoch', idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses, total_loss, final_state, train_step], feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print('第 {0} 步的平均损失 {1}'.format(step, training_loss/100))\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "    return training_losses\n",
    "\n",
    "training_losses = train_rnn(num_epochs=5, num_steps=num_steps, state_size=state_size)\n",
    "print(training_losses[0])\n",
    "plt.plot(training_losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
